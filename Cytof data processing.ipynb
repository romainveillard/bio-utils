{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cytof data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exclu', 'metada']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the folder containing data to analyse\n",
    "folder_path = \"./test_cytof_data\"\n",
    "\n",
    "# Specify the metadata columns\n",
    "metadata_string_columns = []\n",
    "metadata_other_columns = [\"metada\"]\n",
    "metadata_columns = metadata_string_columns + metadata_other_columns\n",
    "\n",
    "# Specify other columns to exclude from processing\n",
    "excluded_columns = [\"exclu\"]\n",
    "\n",
    "# Compute the non data columns in a new variable for easier later use\n",
    "non_data_columns = excluded_columns + metadata_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import common packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 60)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = pd.DataFrame()\n",
    "\n",
    "# Loop over all files in folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Only consider files with '.txt' extension\n",
    "    if filename.endswith('.txt'):\n",
    "        # Build the full path to file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Load the file\n",
    "        events = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "        # Retrieve metadata from the filename (ex: WGANormalised_Pro_PDO21_01.fcs_file_internal...)\n",
    "        # First split: ['WGANormalised_Pro_PDO21_01', '_file_internal']\n",
    "        # Second split over first element: ['WGANormalised', 'Pro', 'PDO21', '01']\n",
    "        metadata_from_filename = filename.split('.fcs')[0].split('_')\n",
    "        # Store the condition name in the dataframe: second-to-last element\n",
    "        events['Condition'] = metadata_from_filename[-2]\n",
    "        # Store the replicate in the dataframe: last element\n",
    "        events['Replicate'] = metadata_from_filename[-1]\n",
    "\n",
    "        # Add the file data to the DataFrame containing all events\n",
    "        all_events = pd.concat([all_events, events], ignore_index=True)\n",
    "\n",
    "# Print all events\n",
    "all_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMD Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the metadata to create a df with only numerical data for normalisation/transformation\n",
    "data = all_events.drop(non_data_columns ,axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure all metadata columns are strings (not numberical as this will run into errors)\n",
    "# metadata = all_data.filter(['Date','Patient','Culture','gd_donor','Transduction','Treatment','Replicate','Time','Batch','Cell_type'])\n",
    "# metadata['Batch'] = metadata['Batch'].apply(str)\n",
    "# metadata['gd_donor'] = metadata['gd_donor'].apply(str)\n",
    "# metadata['Patient'] = metadata['Patient'].apply(str)\n",
    "# metadata['Treatment'] = metadata['Treatment'].apply(str)\n",
    "# metadata['Transduction'] = metadata['Transduction'].apply(str)\n",
    "\n",
    "metadata = all_events.filter(metadata_columns)\n",
    "metadata[metadata_string_columns] = metadata[metadata_string_columns].apply(str)\n",
    "metadata  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a subset of data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batches:\n",
    "#Batch 1 = PDO27wt/ko exp B BM/MOPC21/B7C18\n",
    "#Batch 2 = PDO27 ABCEDF7 Tr\n",
    "#Batch 3 = PDO27 ABCDEF7 NT\n",
    "#Batch 4 = PDO21/23/216 ABE7 Tr\n",
    "#Batch 5 = PDO21/23/216 ABE7 NT \n",
    "#Batch 6 = PDO5/11 ABE7 Tr/NT\n",
    "#Batch 7 = PDO75/99 ABE7 Tr/NT\n",
    "#Batch 8 = PDO109/141 ABE7 Tr/NT\n",
    "#Batch 9 = NT/eGFP/eGFP-stIL15 ABE7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enable this process, set this variable to True, False otherwise\n",
    "should_select_a_subset = False\n",
    "\n",
    "# Define here the filter to apply\n",
    "subset_condition = \\\n",
    "    metadata['Patient'].isin(['X','5','11','21','23','27','75','99','109','141','216']) & \\\n",
    "    metadata['gd_donor'].isin(['A','B','E','7']) & \\\n",
    "    metadata['Transduction'].isin(['eGFP-stIL15']) & \\\n",
    "    metadata['Treatment'].isin(['BM','B7C18']) & \\\n",
    "    metadata['Batch'].isin(['Batch2','Batch4','Batch6','Batch7','Batch8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_select_a_subset:\n",
    "    #Select eGFP-stIL15 / ABE7 / wt PDO / BM / B7C18 (I was just selecting the data I wanted to use)\n",
    "    data = data.loc[subset_condition]\n",
    "    data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_select_a_subset:\n",
    "    #selecting the corresponding metadata\n",
    "    metadata = metadata.loc[subset_condition]\n",
    "    metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arcsinh transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcsinh_cofactor = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcsinh transformation of all raw data\n",
    "data = np.arcsinh(data/arcsinh_cofactor)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch effect correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scprep\n",
    "\n",
    "# Data centering by batch to correct any cytof batch effect\n",
    "# Only if 'Batch' is a metadata\n",
    "if 'Batch' in metadata.columns:\n",
    "    data = scprep.normalize.batch_mean_center(data,sample_idx=metadata['Batch'])\n",
    "    data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-assemble processed data with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate data with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine arcsinh-transformed and mean-centered data with metadata again\n",
    "processed_data = pd.concat([data, metadata], axis=1)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-index the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = processed_data.shape[0]\n",
    "processed_data.index = np.arange(row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure type of metadata column to be string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_data[metadata_string_columns] = processed_data[metadata_string_columns].apply(str)\n",
    "\n",
    "# data_as_meta['Date'] = data_as_meta['Date'].apply(str)\n",
    "# data_as_meta['Patient'] = data_as_meta['Patient'].apply(str)\n",
    "# data_as_meta['Culture'] = data_as_meta['Culture'].apply(str)\n",
    "# data_as_meta['gd_donor'] = data_as_meta['gd_donor'].apply(str)\n",
    "# data_as_meta['Transduction'] = data_as_meta['Transduction'].apply(str)\n",
    "# data_as_meta['Treatment'] = data_as_meta['Treatment'].apply(str)\n",
    "# data_as_meta['Replicate'] = data_as_meta['Replicate'].apply(str)\n",
    "# data_as_meta['Time'] = data_as_meta['Time'].apply(str)\n",
    "# data_as_meta['Batch'] = data_as_meta['Batch'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the `Condition` information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_colmns = ['Patient', 'Culture', 'gd_donor', 'Transduction', 'Treatment', 'Batch', 'Date', 'Replicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the `Condition` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a condition column for every cell in the experiment\n",
    "processed_data['Condition'] = processed_data[condition_colmns].astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "# Add `Condition` to the list of metadata columns\n",
    "metadata_columns += 'Condition'\n",
    "\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the `Control` information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All gd monoculture controls including their transduction, treatment and batch.\n",
    "control_columns = ['gd_donor', 'Transduction', 'Treatment', 'Batch', 'Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the `Control` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define control for pairwise EMD. \n",
    "processed_data['Control'] = \"X_gd_\" + processed_data[control_columns].astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "# Add `Control` to the list of metadata columns\n",
    "metadata_columns += 'Control'\n",
    "\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise EMD dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the markers list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each column in the Dataframe, keep only the ones not in the `metadata_columns` variable\n",
    "markers_list = [col for col in processed_data.columns if col not in metadata_columns]\n",
    "# marker_list = list(processed_data.columns.values)\n",
    "markers_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the conditions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of unique conditions\n",
    "conditions_list = pd.unique(processed_data['Condition'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the controls list (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of unique controls\n",
    "controls_list = pd.unique(processed_data['Control'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the DataFrame that will receive the EMD values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty df with NaN values to populate with the EMD values\n",
    "emd_dataframe = pd.DataFrame(\n",
    "    np.full(\n",
    "        (len(conditions_list), len(markers_list)), \n",
    "        np.nan),\n",
    "    columns = markers_list,\n",
    "    index = conditions_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate EMD scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the conditions\n",
    "for condition in conditions_list:\n",
    "\n",
    "    # Dataframe of all events for the condition in the list\n",
    "    condition_events = processed_data.loc[(processed_data[\"Condition\"] == condition)]\n",
    "\n",
    "    control_name = condition_events['Control'].values[0]\n",
    "    print(control_name)\n",
    "\n",
    "    # Dataframe of all events from the control that will be compared with the events of the current condition\n",
    "    control_df = processed_data.loc[processed_data[\"Condition\"].str.startswith(control_name)]\n",
    "\n",
    "    # Loop over all the markers\n",
    "    for marker in markers_list:\n",
    "\n",
    "        # Check the sign by using the `median` values\n",
    "        sign = np.sign(condition_events[marker].median() - control_df[marker].median())\n",
    "\n",
    "        # In case the median values are equal, use the `mean` instead\n",
    "        if sign == 0:\n",
    "            sign = np.sign(condition_events[marker].mean() - control_df[marker].mean())\n",
    "\n",
    "        # Compute the EMD by multiplying the sign by the EMD score\n",
    "        emd = scprep.stats.EMD(\n",
    "            condition_events[marker], \n",
    "            control_df[marker]\n",
    "        )\n",
    "\n",
    "        # Store the signed EMD in the result Dataframe for the given (condition, marke) pair\n",
    "        emd_dataframe.loc[condition, marker] = sign * emd\n",
    "\n",
    "# Ensure that all (condition, marke) pairs have been properly computed\n",
    "assert not emd_dataframe.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
